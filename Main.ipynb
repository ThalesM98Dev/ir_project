{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T13:23:35.594353Z",
     "start_time": "2024-06-01T13:23:32.948015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from ttkbootstrap import Style\n",
    "from tkinter.scrolledtext import ScrolledText\n",
    "import threading\n",
    "\n",
    "# Ensure NLTK resources are downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ],
   "id": "1b9314d16edb42d7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Thales\n",
      "[nltk_data]     Mustafa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Thales\n",
      "[nltk_data]     Mustafa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Thales\n",
      "[nltk_data]     Mustafa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T13:24:20.465193Z",
     "start_time": "2024-06-01T13:23:36.460412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the functions for loading data and models\n",
    "def load_data_and_models(dataset):\n",
    "    if dataset == 'Clinical Trials':\n",
    "        vectorizer = joblib.load('clinicaltrials/tfidf_vectorizer.pkl')\n",
    "        tfidf_matrix = joblib.load('clinicaltrials/tfidf_matrix.pkl')\n",
    "        df = pd.read_csv('clinicaltrials/clinicaltrials_dataset.csv')\n",
    "    elif dataset == 'Argsme':\n",
    "        vectorizer = joblib.load('argsme/tfidf_vectorizer.pkl')\n",
    "        tfidf_matrix = joblib.load('argsme/tfidf_tfidf_matrix.pkl')\n",
    "        df = pd.read_csv('argsme/argsme_dataset.csv')\n",
    "    original_df = df.copy()\n",
    "    return vectorizer, tfidf_matrix, df, original_df\n",
    "\n",
    "def load_clustering_models(dataset):\n",
    "    if dataset == 'Clinical Trials':\n",
    "        cluster_results = joblib.load('clinicaltrials/combined_cluster_results.pkl')\n",
    "    elif dataset == 'Argsme':\n",
    "        cluster_results = joblib.load('argsme/combined_cluster_results.pkl')\n",
    "    return cluster_results['clusters'], cluster_results['cluster_centers']\n",
    "\n",
    "def load_ground_truth(dataset):\n",
    "    if dataset == 'Clinical Trials':\n",
    "        ground_truth = joblib.load('clinicaltrials/ground_truth.pkl')\n",
    "    elif dataset == 'Argsme':\n",
    "        ground_truth = joblib.load('argsme/ground_truth.pkl')\n",
    "    return ground_truth"
   ],
   "id": "a6a751d64f2d8987",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def preprocess_query(query):\n",
    "    # Implement any necessary query preprocessing steps\n",
    "    return query\n",
    "\n",
    "def vectorize_query(query, vectorizer):\n",
    "    return vectorizer.transform([query])\n",
    "\n",
    "def cluster_based_ranking(query_vector, tfidf_matrix, cluster_labels, cluster_centers):\n",
    "    cluster_similarities = cosine_similarity(query_vector, cluster_centers)\n",
    "    closest_cluster = cluster_similarities.argmax()\n",
    "\n",
    "    cluster_indices = [i for i, label in enumerate(cluster_labels) if label == closest_cluster]\n",
    "\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix[cluster_indices])\n",
    "    rankings = similarities.argsort().flatten()[::-1]\n",
    "\n",
    "    ranked_indices = [cluster_indices[i] for i in rankings]\n",
    "    return ranked_indices\n",
    "\n",
    "def calculate_precision_at_k(relevant_docs, retrieved_docs, k):\n",
    "    return len(set(relevant_docs) & set(retrieved_docs[:k])) / k\n",
    "\n",
    "def calculate_recall(relevant_docs, retrieved_docs):\n",
    "    return len(set(relevant_docs) & set(retrieved_docs)) / len(relevant_docs)\n",
    "\n",
    "def calculate_average_precision(relevant_docs, retrieved_docs):\n",
    "    relevant_set = set(relevant_docs)\n",
    "    ap = 0.0\n",
    "    num_hits = 0\n",
    "    for i, doc_id in enumerate(retrieved_docs):\n",
    "        if doc_id in relevant_set:\n",
    "            num_hits += 1\n",
    "            ap += num_hits / (i + 1)\n",
    "    return ap / len(relevant_docs) if relevant_docs else 0\n",
    "\n",
    "def calculate_reciprocal_rank(relevant_docs, retrieved_docs):\n",
    "    for i, doc_id in enumerate(retrieved_docs):\n",
    "        if doc_id in relevant_docs:\n",
    "            return 1 / (i + 1)\n",
    "    return 0\n",
    "\n",
    "def search():\n",
    "    query = query_entry.get()\n",
    "    if not query:\n",
    "        messagebox.showwarning(\"Input Error\", \"Please enter a search query.\")\n",
    "        return\n",
    "\n",
    "    processed_query = preprocess_query(query)\n",
    "    query_vector = vectorize_query(processed_query, vectorizer)\n",
    "    rankings = cluster_based_ranking(query_vector, tfidf_matrix, cluster_labels, cluster_centers)\n",
    "    top_documents = df.iloc[rankings[:20]]\n",
    "\n",
    "    results_listbox.delete(0, tk.END)\n",
    "    for _, row in top_documents.iterrows():\n",
    "        results_listbox.insert(tk.END, f\"{row['doc_id']}: {row['title'] if dataset_var.get() == 'Clinical Trials' else row['source_title']}\")\n",
    "\n",
    "    if query in ground_truth:\n",
    "        relevant_docs = ground_truth[query]\n",
    "        retrieved_docs = [row['doc_id'] for _, row in top_documents.iterrows()]\n",
    "\n",
    "        p_at_10 = calculate_precision_at_k(relevant_docs, retrieved_docs, 10)\n",
    "        recall = calculate_recall(relevant_docs, retrieved_docs)\n",
    "        ap = calculate_average_precision(relevant_docs, retrieved_docs)\n",
    "        rr = calculate_reciprocal_rank(relevant_docs, retrieved_docs)\n",
    "\n",
    "        metrics_text = f\"Metrics for query '{query}':\\n\"\n",
    "        metrics_text += f\"  Precision@10: {p_at_10:.3f}\\n\"\n",
    "        metrics_text += f\"  Recall: {recall:.3f}\\n\"\n",
    "        metrics_text += f\"  Average Precision: {ap:.3f}\\n\"\n",
    "        metrics_text += f\"  Reciprocal Rank: {rr:.3f}\\n\"\n",
    "        details_text.delete(1.0, tk.END)\n",
    "        details_text.insert(tk.END, metrics_text)\n",
    "\n",
    "# Load data and models for the initial dataset\n",
    "vectorizer, tfidf_matrix, df, original_df = load_data_and_models('Clinical Trials')\n",
    "cluster_labels, cluster_centers = load_clustering_models('Clinical Trials')\n",
    "ground_truth = load_ground_truth('Clinical Trials')\n",
    "\n",
    "def update_data_and_models(event):\n",
    "    global vectorizer, tfidf_matrix, df, original_df, ground_truth, cluster_labels, cluster_centers\n",
    "    dataset = dataset_var.get()\n",
    "    vectorizer, tfidf_matrix, df, original_df = load_data_and_models(dataset)\n",
    "    cluster_labels, cluster_centers = load_clustering_models(dataset)\n",
    "    ground_truth = load_ground_truth(dataset)\n",
    "\n",
    "# GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Document Search with Clustering\")\n",
    "\n",
    "# Dataset selection\n",
    "dataset_var = tk.StringVar()\n",
    "dataset_label = ttk.Label(root, text=\"Select Dataset:\")\n",
    "dataset_label.pack(pady=5)\n",
    "dataset_combobox = ttk.Combobox(root, textvariable=dataset_var, state='readonly')\n",
    "dataset_combobox['values'] = ('Clinical Trials', 'Argsme')\n",
    "dataset_combobox.current(0)\n",
    "dataset_combobox.bind(\"<<ComboboxSelected>>\", update_data_and_models)\n",
    "dataset_combobox.pack(pady=5)\n",
    "\n",
    "# Query input\n",
    "query_label = ttk.Label(root, text=\"Enter Query:\")\n",
    "query_label.pack(pady=5)\n",
    "query_entry = ttk.Entry(root, width=50)\n",
    "query_entry.pack(pady=5)\n",
    "\n",
    "# Search button\n",
    "search_button = ttk.Button(root, text=\"Search\", command=search)\n",
    "search_button.pack(pady=5)\n",
    "\n",
    "# Results listbox\n",
    "results_listbox = tk.Listbox(root, width=100, height=20)\n",
    "results_listbox.pack(pady=5)\n",
    "\n",
    "# Details text box\n",
    "details_text = tk.Text(root, height=10, width=100)\n",
    "details_text.pack(pady=5)\n",
    "\n",
    "# Initialize data and models\n",
    "update_data_and_models(None)\n",
    "\n",
    "root.mainloop()"
   ],
   "id": "598e51f49174ee08"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
